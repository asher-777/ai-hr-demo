import streamlit as st
import os
import pdfplumber
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage

# ==========================================
# 1. é¡µé¢åŸºç¡€é…ç½®
# ==========================================
st.set_page_config(
    page_title="Gemini AI æ‹›è˜åŠ©æ‰‹", 
    page_icon="âš¡", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# 2. ä¾§è¾¹æ ï¼šAPI Key é…ç½®
# ==========================================
with st.sidebar:
    st.header("âš¡ è®¾ç½® / Settings")
    st.markdown("æœ¬ç³»ç»Ÿä½¿ç”¨ **Google Gemini 1.5 Flash** æ¨¡å‹ï¼Œé€Ÿåº¦å¿«ä¸”å…è´¹é¢åº¦é«˜ã€‚")
    
    # ä¼˜å…ˆè¯»å–ç¯å¢ƒå˜é‡ï¼Œå¦åˆ™è®©ç”¨æˆ·è¾“å…¥
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
        os.environ["GOOGLE_API_KEY"] = api_key
        st.success("âœ… ç³»ç»Ÿå¯†é’¥å·²åŠ è½½")
    else:
        api_key = st.text_input("è¯·è¾“å…¥ Google API Key", type="password", placeholder="AIzaå¼€å¤´...")
        if api_key:
            os.environ["GOOGLE_API_KEY"] = api_key
            st.success("âœ… å¯†é’¥å·²ä¿å­˜")
        else:
            st.warning("è¯·å…ˆè¾“å…¥ API Key æ‰èƒ½ä½¿ç”¨ã€‚")
            st.markdown("[ğŸ‘‰ ç‚¹å‡»è¿™é‡Œå…è´¹ç”³è¯· Google Key](https://aistudio.google.com/app/apikey)")

# ==========================================
# 3. åˆå§‹åŒ– Session State (çŠ¶æ€ç®¡ç†)
# ==========================================
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘æ˜¯åŸºäº Gemini çš„ AI é¢è¯•å®˜ã€‚è¯·ä¸Šä¼ ç®€å†ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹æ¨¡æ‹Ÿé¢è¯•ã€‚"}]
if "resume_text" not in st.session_state:
    st.session_state["resume_text"] = ""

# ==========================================
# 4. ä¸»ç•Œé¢æ ‡é¢˜
# ==========================================
st.title("âš¡ Gemini æ™ºèƒ½æ‹›è˜ç³»ç»Ÿ")
st.caption("Powered by Google Gemini 1.5 Flash | æ”¯æŒä¸­è‹±åŒè¯­ç®€å†è§£æ")

# ==========================================
# æ¨¡å— A: ç®€å†è§£æä¸æ™ºèƒ½è¯„åˆ†
# ==========================================
with st.expander("ğŸ“„ ç¬¬ä¸€æ­¥ï¼šç®€å†ä¸Šä¼ ä¸è¯„ä¼° (Resume Analysis)", expanded=True):
    col1, col2 = st.columns([1, 1])
    
    with col1:
        jd_text = st.text_area("è¯·è¾“å…¥èŒä½æè¿° (JD)", height=200, value="å²—ä½ï¼šé«˜çº§é¡¹ç›®ç»ç†\nè¦æ±‚ï¼š\n1. 5å¹´ä»¥ä¸Šè½¯ä»¶è¡Œä¸šç»éªŒã€‚\n2. ç²¾é€šæ•æ·å¼€å‘ (Agile)ã€‚\n3. è‹±è¯­æµåˆ©ï¼Œèƒ½ä½œä¸ºå·¥ä½œè¯­è¨€ã€‚\n4. PMP è¯ä¹¦ä¼˜å…ˆã€‚")
    
    with col2:
        uploaded_file = st.file_uploader("ä¸Šä¼ ç®€å† (æ”¯æŒ PDF)", type="pdf")
        
        if uploaded_file:
            try:
                # ä½¿ç”¨ pdfplumber è§£æ (å¯¹åŒæ æ’ç‰ˆæ›´å‹å¥½)
                with pdfplumber.open(uploaded_file) as pdf:
                    text = ""
                    for page in pdf.pages:
                        extracted = page.extract_text()
                        if extracted:
                            text += extracted + "\n"
                
                st.session_state["resume_text"] = text
                st.success(f"âœ… ç®€å†è§£ææˆåŠŸ (çº¦ {len(text)} å­—ç¬¦)")
                
                # åˆ†ææŒ‰é’®
                if st.button("ğŸš€ å¼€å§‹ AI è¯„ä¼°"):
                    if not api_key:
                        st.error("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ Google API Key")
                    else:
                        with st.spinner("Gemini æ­£åœ¨æé€Ÿåˆ†æä¸­..."):
                            # åˆå§‹åŒ– Gemini æ¨¡å‹
                            llm = ChatGoogleGenerativeAI(
                                model="gemini-1.5-flash",
                                temperature=0.2, # ä½æ¸©åº¦ï¼Œä¿è¯è¯„åˆ†ä¸¥è°¨
                                convert_system_message_to_human=True # å…¼å®¹æ€§è®¾ç½®
                            )
                            
                            prompt = f"""
                            ä½ æ˜¯ä¸€ä½èµ„æ·±çš„äººåŠ›èµ„æºä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹ JD å¯¹ç®€å†è¿›è¡Œè¯¦ç»†è¯„ä¼°ã€‚
                            
                            ã€èŒä½æè¿° JDã€‘:
                            {jd_text}
                            
                            ã€å€™é€‰äººç®€å†ã€‘:
                            {st.session_state["resume_text"]}
                            
                            ã€ä»»åŠ¡è¦æ±‚ã€‘:
                            1. æ— è®ºç®€å†æ˜¯ä¸­æ–‡è¿˜æ˜¯è‹±æ–‡ï¼Œè¯·**å¿…é¡»ä½¿ç”¨ä¸­æ–‡**è¾“å‡ºæŠ¥å‘Šã€‚
                            2. è¯·ä½¿ç”¨ Markdown æ ¼å¼ã€‚
                            3. è¾“å‡ºåŒ…å«ä»¥ä¸‹æ¨¡å—ï¼š
                               - ğŸ“Š **åŒ¹é…åº¦å¾—åˆ†** (0-100åˆ†)
                               - âœ… **æ ¸å¿ƒä¼˜åŠ¿** (åˆ—å‡º3ç‚¹)
                               - âš ï¸ **æ½œåœ¨é£é™©/çº¢æ——** (Red Flags)
                               - ğŸ—£ï¸ **è¯­è¨€èƒ½åŠ›è¯„ä¼°** (é’ˆå¯¹ JD è¦æ±‚çš„è¯­è¨€)
                               - ğŸ’¡ **é¢è¯•å»ºè®®** (2ä¸ªå»ºè®®è¿½é—®çš„é—®é¢˜)
                            """
                            
                            response = llm.invoke([HumanMessage(content=prompt)])
                            st.markdown("### ğŸ“Š è¯„ä¼°æŠ¥å‘Š")
                            st.markdown(response.content)
                            
            except Exception as e:
                st.error(f"è§£æå¤±è´¥: {e}")

# ==========================================
# æ¨¡å— B: AI æ¨¡æ‹Ÿé¢è¯• (Chat)
# ==========================================
st.divider()
st.subheader("ğŸ™ï¸ ç¬¬äºŒæ­¥ï¼šAI æ¨¡æ‹Ÿé¢è¯• (Interactive Interview)")

# 1. å±•ç¤ºèŠå¤©è®°å½•
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# 2. ç”¨æˆ·è¾“å…¥
if user_input := st.chat_input("è¯·è¾“å…¥ä½ çš„å›ç­” (æ”¯æŒä¸­è‹±æ–‡)..."):
    if not api_key:
        st.warning("è¯·å…ˆé…ç½® API Key")
    else:
        # ç”¨æˆ·æ¶ˆæ¯ä¸Šå±
        st.session_state.messages.append({"role": "user", "content": user_input})
        st.chat_message("user").write(user_input)
        
        # AI æ€è€ƒä¸å›å¤
        with st.spinner("é¢è¯•å®˜æ­£åœ¨è®°å½•..."):
            try:
                # åˆå§‹åŒ–èŠå¤©æ¨¡å‹ (ç¨å¾®æé«˜æ¸©åº¦ï¼Œå¢åŠ å¯¹è¯çµæ´»æ€§)
                chat_llm = ChatGoogleGenerativeAI(
                    model="gemini-1.5-flash",
                    temperature=0.6,
                    convert_system_message_to_human=True
                )
                
                # æ„å»º Prompt
                system_prompt = f"""
                You are a professional Interviewer.
                Current Job: {jd_text}
                Candidate Resume Content: {st.session_state.get('resume_text', 'No resume uploaded yet')}
                
                **Rules**:
                1. If user speaks Chinese, reply in Chinese.
                2. If user speaks English, reply in English.
                3. Ask **ONE** question at a time.
                4. Use the STAR method to dig into details based on the resume.
                5. Be professional but slightly challenging.
                """
                
                # æ„å»ºæ¶ˆæ¯å†å² (Gemini å¯¹ SystemMessage çš„å¤„ç†æ–¹å¼ä¸åŒï¼Œæˆ‘ä»¬å°†å…¶ä½œä¸ºç¬¬ä¸€æ¡ HumanMessage çš„ä¸Šä¸‹æ–‡å‰ç¼€ï¼Œæˆ–è€…ä½¿ç”¨ LangChain çš„è‡ªåŠ¨è½¬æ¢)
                messages = [SystemMessage(content=system_prompt)]
                
                # ä»…ä¿ç•™æœ€è¿‘ 10 æ¡å¯¹è¯ï¼Œé˜²æ­¢ Token æº¢å‡º
                for msg in st.session_state.messages[-10:]:
                    if msg["role"] == "user":
                        messages.append(HumanMessage(content=msg["content"]))
                    else:
                        # LangChain ä¸­ AI çš„å›å¤å¯¹åº” AIMessageï¼Œè¿™é‡Œä¸ºäº†ç®€å•ç›´æ¥ç”¨ System æ¨¡æ‹Ÿæˆ–ç›´æ¥ç”±åº“å¤„ç†
                        # åœ¨ ChatGoogleGenerativeAI ä¸­ï¼Œæœ€å¥½ä¸è¦æ‰‹åŠ¨æ’å…¥ AIMessage ç±»ï¼Œè€Œæ˜¯ä¾é  LangChain çš„ invoke ç»“æ„
                        # ç®€å•èµ·è§ï¼Œæˆ‘ä»¬åªæŠŠç”¨æˆ·çš„å†å²å‘ç»™å®ƒï¼Œæˆ–è€…ä½¿ç”¨ memory chainã€‚
                        # ä¸ºäº†æœ€ç®€å•çš„å®ç°ï¼š
                        pass 
                
                # âš ï¸ ä¿®æ­£ï¼šä¸ºäº†è®© Gemini è®°ä½ä¸Šä¸‹æ–‡ï¼Œæˆ‘ä»¬éœ€è¦æŠŠå†å²å¯¹è¯è½¬æ¢æˆå®ƒèƒ½ç†è§£çš„æ ¼å¼
                # æœ€ç®€å•çš„æ–¹æ³•æ˜¯å°†å†å²è®°å½•æ‹¼æ¥æˆä¸€ä¸ªé•¿ Prompt å‘é€ï¼ˆæ— çŠ¶æ€æ¨¡å¼ï¼‰ï¼Œæˆ–è€…ä½¿ç”¨ LangChain çš„ Memory
                # è¿™é‡Œé‡‡ç”¨â€œæ‹¼æ¥æ³•â€ç¡®ä¿ç¨³å®šæ€§ï¼š
                
                full_conversation = system_prompt + "\n\nConversation History:\n"
                for msg in st.session_state.messages:
                    role_label = "Candidate" if msg["role"] == "user" else "Interviewer"
                    full_conversation += f"{role_label}: {msg['content']}\n"
                
                full_conversation += "Interviewer (You):"
                
                ai_response = chat_llm.invoke([HumanMessage(content=full_conversation)])
                
                # AI å›å¤ä¸Šå±
                st.session_state.messages.append({"role": "assistant", "content": ai_response.content})
                st.chat_message("assistant").write(ai_respons
